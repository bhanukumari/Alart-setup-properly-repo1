# File contains default list of alerts for VictoriaMetrics single server.
# The alerts below are just recommendations and may require some updates
# and threshold calibration according to every specific setup.
groups:
  # Alerts group for VM single assumes that Grafana dashboard
  # https://grafana.com/grafana/dashboards/10229 is installed.
  # Pls update the `dashboard` annotation according to your setup.
  - name: vmsingle
    interval: 30s
    concurrency: 2
    rules:
      - alert: RequestErrorsToAPI
        expr: rate(flask_http_request_total{status="500"}[5m]) > 0
        labels:
          severity: warning
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Too many errors served for path {{ $labels.path }} (instance {{ $labels.instance }})"
          description: "Requests to path {{ $labels.path }} are receiving errors.
            Please verify if clients are sending correct requests."

      - alert: TooHighChurnRate
        expr: |
          (
             sum(rate(vm_new_timeseries_created_total[5m])) by(instance)
             /
             sum(rate(vm_rows_inserted_total[5m])) by(instance)
           ) > 0.1
        for: 15m
        labels:
          severity: warning
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Churn rate is more than 10% on \"{{ $labels.instance }}\" for the last 15m"
          description: "VM constantly creates new time series on \"{{ $labels.instance }}\".\n
            This effect is known as Churn Rate.\n
            High Churn Rate tightly connected with database performance and may
            result in unexpected OOM's or slow queries."

      - alert: TooHighChurnRate24h
        expr: |
          sum(increase(vm_new_timeseries_created_total[24h])) by(instance)
          >
          (sum(vm_cache_entries{type="storage/hour_metric_ids"}) by(instance) * 3)
        for: 15m
        labels:
          severity: warning
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Too high number of new series on \"{{ $labels.instance }}\" created over last 24h"
          description: "The number of created new time series over last 24h is 3x times higher than
            current number of active series on \"{{ $labels.instance }}\".\n
            This effect is known as Churn Rate.\n
            High Churn Rate tightly connected with database performance and may
            result in unexpected OOM's or slow queries."

      - alert: TooHighSlowInsertsRate
        expr: |
          (
             sum(rate(vm_slow_row_inserts_total[5m])) by(instance)
             /
             sum(rate(vm_rows_inserted_total[5m])) by(instance)
           ) > 0.05
        for: 15m
        labels:
          severity: warning
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Percentage of slow inserts is more than 5% on \"{{ $labels.instance }}\" for the last 15m"
          description: "High rate of slow inserts on \"{{ $labels.instance }}\" may be a sign of resource exhaustion
            for the current load. It is likely more RAM is needed for optimal handling of the current number of active time series."
      - alert: HighMemoryUsageAndLowFree
        expr: |
          (system_memory_utilization_ratio > 0.8)
           and
          (avg_over_time(system_memory_limit_bytes - system_memory_usage_bytes)[5m] <= 500 * 1024 * 1024)
        for: 5m
        labels:
          severity: critical
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Memory usage is high and available memory is critically low"
          description: "High memory usage and low available memory on instance {{ $labels.instance }}. Current value: {{ printf \"%.2f\" ($value) }}%"

      - alert: HighCPUUtilization
        expr: avg by (instance) (system_cpu_utilization_ratio) * 100 > 85
        for: 5m
        labels:
          severity: critical
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "High CPU Utilization on {{ $labels.instance }}"
          description: "CPU utilization on {{ $labels.instance }} is above 85% for the last 5 minutes. Current value: {{ printf \"%.2f\" ($value) }}%"

      - alert: HighDiskSpaceUtilization
        expr: avg by (instance, mountpoint) (system_filesystem_utilization_ratio) * 100 > 85
        for: 5m
        labels:
          severity: critical
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "High Disk Space Utilization on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          description: "Disk space utilization on {{ $labels.instance }} for mount point {{ $labels.mountpoint }} is above 85% for the last 5 minutes. Current value: {{ printf \"%.2f\" ($value) }}%"
      - alert: TooManyRestarts
        expr: changes(process_start_time_seconds{job=~".*(victoriametrics|vmagent|vmalert|vmalertmanager).*"}[5m]) > 0
        labels:
          severity: critical
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "{{ $labels.job }} too many restarts (instance {{ $labels.instance }})"
          description: 
            "Job {{ $labels.job }} (instance {{ $labels.instance }}) has restarted more than twice in the last 5 minutes. It might be crashlooping."

      - alert: ServiceDown
        expr: up{job=~".*(victoriametrics|vmagent|vmalert|vmsingle|vmalertmanager).*"} == 0
        for: 2m
        labels:
          severity: critical
          channel: slack
          team: devops
        annotations:
          dashboard: "http://localhost:3000"
          summary: "Service {{ $labels.job }} is down on {{ $labels.instance }}"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes."
